{
    "collab_server" : "",
    "contents" : "## Data Load ----\ndata_set = read.csv('HR_Employee_Attrition_Data.csv', header = T)\ntable(sapply(data_set,class))\nfactor_feildIDs=which(sapply(data_set, class) == \"factor\")\ninteger_feildIDs=which(sapply(data_set, class) == \"integer\")\n## Data Split ----\nlibrary(caTools)\nset.seed(123)\nsplit_vector = sample.split(data_set$Attrition,SplitRatio = 0.7)\nDev_Original = subset(data_set, split_vector==T)\nHoldOut_Original = subset(data_set, split_vector ==F)\nDev_data = Dev_Original\nHoldOut_data = HoldOut_Original\n## Visual representation of each variable contribution to Attrition ----\nrequire(ggplot2)\n# bar plots for all the factor variables\nfor( i in factor_feildIDs){\n  name = paste(names(Dev_data[i]),'.png', sep = '')\n  png(filename =paste0('plots/',name), width = 800, height = 600, units = 'px')\n  print(ggplot( Dev_data,\n                aes(x=Dev_data[,i],\n                    fill =Dev_data$Attrition))+\n          xlab(names(Dev_data[i]))+\n          ylab('Frequency')+\n          geom_bar(position = 'dodge')+\n          guides(fill = guide_legend('Attrition')))\n  dev.off()\n  print.noquote(names(Dev_data[i]))\n  print.noquote(summary(Dev_data[,i]))\n}\n# single category variable in categorical type variables \nfor(i in factor_feildIDs){\n  if(length(levels(Dev_data[,i]))==1){\n    print.noquote(paste0(names(Dev_data[i]),' has only 1 category and its field id is ',i))\n  }\n}\n# single valued variable in interger type\nfor( i in integer_feildIDs){\n  if(max(Dev_data[,i])==min(Dev_data[,i])){\n    print.noquote(paste0('All the values of ',names(Dev_data[i]),' are : ',\n                         max(Dev_data[,i]),' and its ID is : ',i ))\n  }\n}\n# correlation plots for all interger variables\nrequire(gclus)\ncor_int_data1 = Dev_data[c(head(integer_feildIDs,13))]\ncor_int_data2 = Dev_data[c(tail(integer_feildIDs,13))]\npng(filename = 'plots/Correlation_1.png', width = 1600, height = 1200, units = 'px')\ncpairs(data = cor_int_data1,\n       panel.colors = dmat.color(abs(cor(cor_int_data1))),\n       gap =0.5)\ndev.off()\npng(filename = 'plots/Correlation_2.png', width = 1600, height = 1200, units = 'px')\ncpairs(data = cor_int_data2,\n       panel.colors = dmat.color(abs(cor(cor_int_data2))),\n       gap =0.5)\ndev.off() \nrm(list = c(\"cor_int_data1\",\n            \"cor_int_data2\",\"i\",\"name\"))\n## Missing data Check -----\nMissing_data_Check <- function(data_set){\n  NA_Count = sapply(data_set,function(y) sum(length(which(is.na(y))))) \n  Null_Count = sapply(data_set,function(y) sum(length(which(is.null(y)))))\n  Length0_Count = sapply(data_set,function(y) sum(length(which(length(y)==0))))\n  Empty_Count = sapply(data_set,function(y) sum(length(which(y==''))))\n  Total_NonData = NA_Count+Null_Count+Length0_Count+Empty_Count\n  return( Total_NonData )\n}\n\nif(length(which(Missing_data_Check(Dev_data)>0))==0){\n  print(\"No Missing data\")\n}else{\n  which(Missing_data_Check(Dev_data)>0)\n}\n\n## Removing non-useful data ----\nDev_data = Dev_data[,-c(9,10,22,27)] # removing 'Over18','EmployeeCount','StandardHours','Employeenumber'\nHoldOut_data = HoldOut_data[,-c(9,10,22,27)]\n## Random Forset on Holdout data & Tunning  ----\nlibrary(randomForest)\n# Dense Forest\nset.seed(123)\nRF_model = randomForest(x = Dev_data[-2],\n                        y = Dev_data$Attrition,\n                        data_set = Dev_data,\n                        ntree =  5000,  # large number because we want to build as many trees as possible\n                        mtry =  6,\n                        nodesize = 40)\nRF_model\nplot(RF_model, main = \"High number of trees vs OOB error\")\n# Adjusted forest based on previous plot\nset.seed(123)\nRF_model = randomForest(x = Dev_data[-2],\n                        y = Dev_data$Attrition,\n                        data_set = Dev_data,\n                        ntree =  500,\n                        mtry =  6,\n                        nodesize = 40)\nRF_model\nplot(RF_model, main = \"Adjusted tree number vs OOB error\")\n# Adjusting mtry - 2 techinques - tureRF and gridsearch\nset.seed(321)\ntuned_RF_model = tuneRF(x = Dev_data[-2],\n                        y = Dev_data$Attrition,\n                        data_set = Dev_data,\n                        mtryStart = 2,\n                        stepFactor = 1.5,\n                        improve = 0.001,\n                        ntreeTry = 500,\n                        nodesize = 40,\n                        doBest = T, trace = T, plot = T,importance = T)\ntuned_RF_model #tune_RF - 19\nlibrary(caret)\nset.seed(123)\ngrid_RF_tune = train(x = Dev_data[-2],\n                     y = Dev_data$Attrition,\n                     method = 'rf')\ngrid_RF_tune #gridsearch gives 16\n\ntemp_dev_acc = numeric()\ntemp_nodesize = numeric()\ntemp_hold_acc = numeric()\nj = 1\nfor (i in seq(from = 1, to = 90 , by = 3)){\n  set.seed(123)\n  RF_model = randomForest(x = Dev_data[-2],\n                          y = Dev_data$Attrition,\n                          data_set = Dev_data,\n                          ntree =  500,\n                          mtry =  19,\n                          nodesize = i)\n  if(RF_model$confusion[1]!=2058 & RF_model$confusion[2]!=2058){\n    temp_dev_acc[j] = (RF_model$confusion[1]+RF_model$confusion[4])/2058\n    temp_nodesize[j] = i\n    holdout_prediction = predict(RF_model, newdata = HoldOut_data, type ='class')\n    table = table(HoldOut_data$Attrition,holdout_prediction)\n    temp_hold_acc[j] = (table[1]+table[4])/882\n    j = j+1\n  }\n}\nnodesize_df = data.frame(x=temp_nodesize,y1=temp_dev_acc,y2=temp_hold_acc)\nlibrary(ggplot2)\n#png('plots/node_size.png',width = 800, height = 600, units = 'px')\nggplot() +\n  geom_line(data = nodesize_df,\n            aes(nodesize_df$x,nodesize_df$y1),col = 'red')+\n  # geom_line(data = nodesize_df,\n  #           aes(nodesize_df$x,nodesize_df$y2),col = 'green')+\n  xlab('node size')+\n  ylab('accuracy')+\n  ggtitle('ntree is 500 & mtry is 19')\n#dev.off()\n# final Random forest ------\nset.seed(123)\nRF_model = randomForest(x = Dev_data[-2],\n                        y = Dev_data$Attrition,\n                        data_set = Dev_data,\n                        ntree =  500,\n                        mtry =  19,\n                        nodesize = 2)\nRF_model\nplot(RF_model)\nrm(list = c(\"nodesize_df\",\"holdout_prediction\",\"i\",\"j\",\n            \"temp_nodesize\",\"temp_dev_acc\",\"temp_hold_acc\",\"table\"))\nDev_Original$RF_Prob = predict(RF_model,newdata = Dev_data, type='prob')\nDev_Original$RF_Prob =Dev_Original$RF_Prob[,2]\nHoldout_prediction_Prob = predict(RF_model,newdata = HoldOut_data, type='prob')\nHoldout_prediction_class =predict(RF_model,newdata = HoldOut_data, type='class')\nHoldOut_data$RF_prob =Holdout_prediction_Prob[,2]\nHoldOut_data$RF_class = Holdout_prediction_class\nHoldOut_Original$RF_prob = HoldOut_data$RF_prob\nHoldOut_Original$RF_Class = Holdout_prediction_class\n\n# Classification \nConfusion_Matrix_RF=addmargins(table(actual = HoldOut_data$Attrition, Prediction = HoldOut_data$RF_class))\nConfusion_Matrix_RF\nAccuracy_RF=(Confusion_Matrix_RF[1]+Confusion_Matrix_RF[5])/Confusion_Matrix_RF[9]*100\nAccuracy_RF #96.82 %\n\n# KS Ranking \ndecile <- function(x){\n  deciles = vector(length=10)\n  for (i in seq(0.1,1,.1)){\n    deciles[i*10] <- quantile(x, i, na.rm=T)\n  }\n  return (\n    ifelse(x<deciles[1], 1,\n    ifelse(x<deciles[2], 2,\n    ifelse(x<deciles[3], 3,\n    ifelse(x<deciles[4], 4,\n    ifelse(x<deciles[5], 5,\n    ifelse(x<deciles[6], 6,\n    ifelse(x<deciles[7], 7,\n    ifelse(x<deciles[8], 8,\n    ifelse(x<deciles[9], 9, 10 ))))))))))\n}\nHoldOut_data$decile = decile(Holdout_prediction_Prob[,2])\nrequire(data.table)\nrequire(scales)\nHoldOut_data$Attrition_Numeric = ifelse(HoldOut_data$Attrition==\"No\",0,1)\n\nRanking <-function(tmp_DT){\n  rank = tmp_DT[, list(\n    cnt = length(Attrition_Numeric), \n    cnt_resp = sum(Attrition_Numeric), \n    cnt_non_resp = sum(Attrition_Numeric == 0)) , \n    by=decile][order(-decile)]\n  rank$rrate <- round (rank$cnt_resp / rank$cnt,2);\n  rank$cum_resp <- cumsum(rank$cnt_resp)\n  rank$cum_non_resp <- cumsum(rank$cnt_non_resp)\n  rank$cum_rel_resp <- round(rank$cum_resp / sum(rank$cnt_resp),2);\n  rank$cum_rel_non_resp <- round(rank$cum_non_resp / sum(rank$cnt_non_resp),2);\n  rank$ks <- abs(rank$cum_rel_resp - rank$cum_rel_non_resp);\n  rank$rrate <- percent(rank$rrate)\n  rank$cum_rel_resp <- percent(rank$cum_rel_resp)\n  rank$cum_rel_non_resp <- percent(rank$cum_rel_non_resp)\n  \n  return(rank)\n}\n\nHoldout_RF_Ranking = Ranking(data.table(HoldOut_data))\n\nDev_data$Attrition_Numeric = ifelse(Dev_data$Attrition==\"No\",0,1)\nDev_data_Prob = predict(RF_model,newdata = Dev_data, type='prob')\nDev_data_class =predict(RF_model,newdata = Dev_data, type='class')\nDev_data$RF_prob =Dev_data_Prob[,2]\nDev_data$decile = decile(Dev_data_Prob[,2])\nDev_data$RF_class = Dev_data_class\nDev_RF_Ranking = Ranking(data.table((Dev_data)))\n\nView(Holdout_RF_Ranking)\nView(Dev_RF_Ranking)\nhist(HoldOut_data$RF_prob)\nhist(Dev_data$RF_prob)\nrm(list = c(\"Dev_data_Prob\",\"Holdout_prediction_Prob\",\"Dev_data_class\",\n            \"Holdout_prediction_class\"))\n\n## NueralNet -----\nInteger_dataset= data_set[,c(integer_feildIDs,factor_feildIDs)]\nInteger_dataset = Integer_dataset[,-c(5,6,18,34)] # removing 'Over18','EmployeeCount','EmployeeNumber','StandardHours'\n\ntemp <- data.frame(model.matrix(~ BusinessTravel - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\ntemp <- data.frame(model.matrix(~ Department - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\ntemp <- data.frame(model.matrix(~ EducationField - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\ntemp <- data.frame(model.matrix(~ Gender - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\ntemp <- data.frame(model.matrix(~ JobRole - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\ntemp <- data.frame(model.matrix(~ MaritalStatus - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\ntemp <- data.frame(model.matrix(~ OverTime - 1, data = Integer_dataset))\nInteger_dataset <- data.frame(Integer_dataset, temp[-1])\nnames(Integer_dataset)\n\nInteger_dataset =Integer_dataset[,-c(25:31)]\nnames(Integer_dataset)\n\n\nInteger_dataset$Attrition = as.numeric(as.character(factor(Integer_dataset$Attrition,\n                                                           levels = c(\"No\",\"Yes\"),\n                                                           labels = c(0,1))))\nwhich(sapply(Integer_dataset, class) == \"factor\")\nrequire(caret)\nset.seed(123)\nsplit_vector = sample.split(Integer_dataset$Attrition,SplitRatio = 0.7)\ndev_data_int = subset(Integer_dataset, split_vector ==T)\nhold_data_int = subset(Integer_dataset, split_vector ==F)\n\n\nfor(i in 1:45){\n  if(i!=24){\n    dev_data_int[i] = scale(dev_data_int[i])\n  }\n}\n\nrequire(neuralnet)\nn = names(dev_data_int)\nlong_formula = as.formula(paste(\"Attrition ~\", paste(n[!n %in% \"Attrition\"], collapse = \" + \")))\nset.seed(123)\nNN_model_int = neuralnet(formula = long_formula,\n                         data = dev_data_int,\n                         hidden = 10,\n                         err.fct = \"sse\",\n                         linear.output = FALSE,\n                         lifesign = \"full\",\n                         lifesign.step = 1,\n                         threshold = 0.01,\n                         stepmax = 4000)\nplot(NN_model_int)\ndev_NN_pred = NN_model_int$net.result[[1]]\ndev_df = data.frame(dev_NN_pred,dev_data_int$Attrition)\nDev_Original$NN_prob =dev_NN_pred\ndev_NN_pred = ifelse(dev_NN_pred>=0.5,1,0)\ntable = addmargins(table(dev_data_int$Attrition,dev_NN_pred)) # ~98.4%\ntable\ndev_NN_acc = (table[1]+table[5])/table[9]\ndev_NN_acc\n\nfor(i in 1:45){\n  if(i!=24){\n    hold_data_int[i] = scale(hold_data_int[i])\n  }\n}\n\nholdout_NN_pred = compute(NN_model_int,hold_data_int[,-24])\nholdout_NN_pred = holdout_NN_pred$net.result\nhold_df = data.frame(holdout_NN_pred,hold_data_int$Attrition)\nHoldOut_Original$NN_Pred = holdout_NN_pred\nholdout_NN_pred = ifelse(holdout_NN_pred>=0.5,1,0)\ntable =addmargins(table(hold_data_int$Attrition,holdout_NN_pred)) # ~94.5\ntable\nhold_NN_acc = (table[1]+table[5])/table[9]\nhold_NN_acc\n\n# Ensembling  -------\nDev_Original$Attrition = ifelse(Dev_Original$Attrition==\"No\",0,1)\nDev_Original$RF_Class = ifelse(Dev_data$RF_class==\"No\",0,1)\nDev_Original$NN_Class = dev_NN_pred\n\nDev_Original$Ensemble_prod = (Dev_Original$RF_Prob + Dev_Original$NN_prob)/2\nDev_Original$Class = ifelse(Dev_Original$Ensemble_prod>=0.3,1,0)\n\ntable =addmargins(table(Dev_Original$Attrition,Dev_Original$Class)) # 99.8 %\ntable\ndev_Ensemble_acc = (table[1]+table[5])/table[9]\ndev_Ensemble_acc\n\nHoldOut_Original$Attrition = ifelse(HoldOut_Original$Attrition==\"No\",0,1)\nHoldOut_Original$RF_Class = ifelse(HoldOut_Original$RF_Class==\"No\",0,1)\nHoldOut_Original$NN_Class = holdout_NN_pred\n\nHoldOut_Original$Ensemble_prod = (HoldOut_Original$RF_prob+HoldOut_Original$NN_Pred)/2\nHoldOut_Original$Class = ifelse(HoldOut_Original$Ensemble_prod>=0.3,1,0)\n\ntable =addmargins(table(HoldOut_Original$Attrition,HoldOut_Original$Class)) # ~96.03\ntable\nhold_Ensemble_acc = (table[1]+table[5])/table[9]\nhold_Ensemble_acc\n\n",
    "created" : 1511461624686.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3166621420",
    "id" : "2D5BC4D8",
    "lastKnownWriteTime" : 1514999655,
    "last_content_update" : 1514999655592,
    "path" : "~/GitHub/MachineLearningExamples/Classification/HR_Attrition/HR_Attrition.R",
    "project_path" : "HR_Attrition.R",
    "properties" : {
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}